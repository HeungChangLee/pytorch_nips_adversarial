{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, copy, numpy as np\n",
    "from livelossplot import PlotLosses\n",
    "from train_model_it import train_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'aug1': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop()\n",
    "        transforms.RandomHorizontalFlip(1),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'aug2': transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "#     'aug3': transforms.Compose([\n",
    "#         transforms.RandomCrop(224),\n",
    "#         transforms.ToTensor()\n",
    "#     ]),\n",
    "#     'aug4': transforms.Compose([\n",
    "#         transforms.RandomCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(1),\n",
    "#         transforms.ToTensor()\n",
    "#     ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_datasets =  datasets.ImageFolder('/disk/LHC/images/71_60to70/train', data_transforms['train'])\n",
    "augmt1_datasets = datasets.ImageFolder('/disk/LHC/images/71_60to70/train_noise', data_transforms['train'])\n",
    "# augmt2_datasets = datasets.ImageFolder('/disk/MTJ/images/71/val_noise', data_transforms['val'])\n",
    "# augmt3_datasets = datasets.ImageFolder('tiny-imagenet-200-256/train', data_transforms['aug3'])\n",
    "# augmt4_datasets = datasets.ImageFolder('tiny-imagenet-200-256/train', data_transforms['aug4'])\n",
    "valid_datasets =  datasets.ImageFolder('/disk/LHC/images/71_60to70/val',   data_transforms['val'])\n",
    "\n",
    "concat = torch.utils.data.ConcatDataset([\n",
    "    train_datasets,\n",
    "    augmt1_datasets,\n",
    "#     augmt2_datasets,\n",
    "#     augmt3_datasets,\n",
    "#     augmt4_datasets,\n",
    "])\n",
    "\n",
    "# concat2 = torch.utils.data.ConcatDataset([\n",
    "#     valid_datasets,\n",
    "# #     augmt2_datasets,\n",
    "# #     augmt3_datasets,\n",
    "# #     augmt4_datasets,\n",
    "# ])\n",
    "batch_size = 1000\n",
    "dataloaders = {\n",
    "    'train' : torch.utils.data.DataLoader(concat, batch_size=batch_size, shuffle=True, num_workers=100),\n",
    "    'val'   : torch.utils.data.DataLoader(valid_datasets, batch_size=100, shuffle=False, num_workers=100)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train' : len(concat),\n",
    "    'val'   : len(valid_datasets)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Resnet18 with pretrained weights\n",
    "model_ft = models.resnet18()\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "model_ft.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "model_ft.maxpool = nn.Sequential()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "#Multi GPU\n",
    "model_ft = torch.nn.DataParallel(model_ft, device_ids=[0,1,2,3,4,5,6,7])\n",
    "#Load 256x256 tiny-imagenet trained ResNet18\n",
    "pretrained_dict = torch.load('/disk/LHC/models/nips_resnet18_64_noise_pretrained_256_with_val_noise_weight.pt')\n",
    "model_ft_dict = model_ft.state_dict()\n",
    "\n",
    "#Reset 1st layer weight\n",
    "first_layer_weight = model_ft_dict['module.conv1.weight']\n",
    "first_layer_bias  = model_ft_dict['module.conv1.bias']\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_ft_dict}\n",
    "\n",
    "model_ft_dict.update(pretrained_dict) \n",
    "model_ft_dict['module.conv1.weight'] = first_layer_weight\n",
    "model_ft_dict['module.conv1.bias']   = first_layer_bias\n",
    "\n",
    "#Load pretrained weight from layer 2~18\n",
    "model_ft.load_state_dict(model_ft_dict)\n",
    "\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "model_ft = train_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       batch_size=batch_size, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, \"./models/nips_resnet18_71_noise_aug_pretrained_64_noise_bt2000.pt\") \n",
    "torch.save(model_ft.state_dict(), \"./models/nips_resnet18_71_noise_aug_pretrained_64_noise_bt2000_weight.pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
